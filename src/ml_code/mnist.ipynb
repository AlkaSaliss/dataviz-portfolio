{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from IPython.display import display, HTML\n",
    "\n",
    "# display(HTML(data=\"\"\"\n",
    "# <style>\n",
    "#     div#notebook-container    { width: 95%; }\n",
    "#     div#menubar-container     { width: 65%; }\n",
    "#     div#maintoolbar-container { width: 99%; }\n",
    "# </style>\n",
    "# \"\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "import torch.optim as optim\n",
    "from model_utils import run_training, create_train_folders\n",
    "from data_utils import MnistDataset, get_dataloader\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "TRAIN_BATCH_SIZE = 512\n",
    "TEST_BATCH_SIZE = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "        ])\n",
    "dataset1 = datasets.MNIST('./ml_outputs/', train=True, transform=transform, download=True)\n",
    "dataset2 = datasets.MNIST('./ml_outputs/', train=False, transform=transform, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60000, 10000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset1), len(dataset2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get Data loaders\n",
    "\n",
    "train_loader = get_dataloader(dataset1, TRAIN_BATCH_SIZE)\n",
    "test_loader = get_dataloader(dataset2, TRAIN_BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MODELS CLASSES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Net2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net2, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.bn1 = nn.BatchNorm2d(32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.bn2 = nn.BatchNorm2d(64)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.bn1(self.conv1(x))\n",
    "        x = F.relu(x)\n",
    "        x = self.bn2(self.conv2(x))\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir, log_dir = create_train_folders(\"ml_outputs/run1\")\n",
    "model = Net1()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "sched = optim.lr_scheduler.StepLR(opt, 20, 0.6)\n",
    "conf1 = {\n",
    "    \"model\": model,\n",
    "    \"optimizer\": opt,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": test_loader,\n",
    "    \"epochs\": 100,\n",
    "    \"ckpt_dir\": ckpt_dir,\n",
    "    \"log_dir\": log_dir,\n",
    "    \"scheduler\": sched,\n",
    "    \"patience\": 20,\n",
    "    \"fname\": \"run1\",\n",
    "    \"label_smooth\": 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_training(**conf1)\n",
    "\n",
    "# CPU times: user 4min 34s, sys: 13.4 s, total: 4min 48s\n",
    "# Wall time: 4min 43s\n",
    "# {'train_loss': 0.10791252932548523,\n",
    "#  'val_loss': 0.10492422745227814,\n",
    "#  'train_acc': 0.9678,\n",
    "#  'val_acc': 0.9659}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir, log_dir = create_train_folders(\"ml_outputs/run2\")\n",
    "model = Net1()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "sched = optim.lr_scheduler.StepLR(opt, 20, 0.6)\n",
    "conf1 = {\n",
    "    \"model\": model,\n",
    "    \"optimizer\": opt,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": test_loader,\n",
    "    \"epochs\": 100,\n",
    "    \"ckpt_dir\": ckpt_dir,\n",
    "    \"log_dir\": log_dir,\n",
    "    \"scheduler\": sched,\n",
    "    \"patience\": 20,\n",
    "    \"fname\": \"run1\",\n",
    "    \"label_smooth\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_training(**conf1)\n",
    "\n",
    "# CPU times: user 4min 24s, sys: 12.8 s, total: 4min 36s\n",
    "# Wall time: 4min 31s\n",
    "# {'train_loss': 0.7046732180277506,\n",
    "#  'val_loss': 0.6972992223739624,\n",
    "#  'train_acc': 0.9482833333333334,\n",
    "#  'val_acc': 0.9503}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir, log_dir = create_train_folders(\"ml_outputs/run3\")\n",
    "model = Net1()\n",
    "opt = optim.RMSprop(model.parameters(), lr=1e-2)\n",
    "sched = optim.lr_scheduler.StepLR(opt, 10, 0.8)\n",
    "conf1 = {\n",
    "    \"model\": model,\n",
    "    \"optimizer\": opt,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": test_loader,\n",
    "    \"epochs\": 100,\n",
    "    \"ckpt_dir\": ckpt_dir,\n",
    "    \"log_dir\": log_dir,\n",
    "    \"scheduler\": sched,\n",
    "    \"patience\": 30,\n",
    "    \"fname\": \"run1\",\n",
    "    \"label_smooth\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_training(**conf1)\n",
    "\n",
    "# CPU times: user 6min 23s, sys: 18.5 s, total: 6min 42s\n",
    "# Wall time: 6min 34s\n",
    "# {'train_loss': 1.173741497039795,\n",
    "#  'val_loss': 1.165649961090088,\n",
    "#  'train_acc': 0.8259333333333333,\n",
    "#  'val_acc': 0.8339}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir, log_dir = create_train_folders(\"ml_outputs/run4\")\n",
    "model = Net1()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-2)\n",
    "sched = optim.lr_scheduler.StepLR(opt, 10, 0.8)\n",
    "conf1 = {\n",
    "    \"model\": model,\n",
    "    \"optimizer\": opt,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": test_loader,\n",
    "    \"epochs\": 100,\n",
    "    \"ckpt_dir\": ckpt_dir,\n",
    "    \"log_dir\": log_dir,\n",
    "    \"scheduler\": sched,\n",
    "    \"patience\": 30,\n",
    "    \"fname\": \"run1\",\n",
    "    \"label_smooth\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_training(**conf1)\n",
    "\n",
    "# CPU times: user 5min 53s, sys: 17.2 s, total: 6min 10s\n",
    "# Wall time: 6min 4s\n",
    "# {'train_loss': 0.7110810436248779,\n",
    "#  'val_loss': 0.7032975393295288,\n",
    "#  'train_acc': 0.9472333333333334,\n",
    "#  'val_acc': 0.9516}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir, log_dir = create_train_folders(\"ml_outputs/run5\")\n",
    "model = Net1()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "sched = None\n",
    "conf1 = {\n",
    "    \"model\": model,\n",
    "    \"optimizer\": opt,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": test_loader,\n",
    "    \"epochs\": 100,\n",
    "    \"ckpt_dir\": ckpt_dir,\n",
    "    \"log_dir\": log_dir,\n",
    "    \"scheduler\": sched,\n",
    "    \"patience\": 30,\n",
    "    \"fname\": \"run1\",\n",
    "    \"label_smooth\": 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_training(**conf1)\n",
    "\n",
    "# CPU times: user 6min 37s, sys: 19.3 s, total: 6min 56s\n",
    "# Wall time: 6min 48s\n",
    "# {'train_loss': 0.007712779863427083,\n",
    "#  'val_loss': 0.025506638836860655,\n",
    "#  'train_acc': 0.9981666666666666,\n",
    "#  'val_acc': 0.9916}\n",
    "# 1\n",
    "# ​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir, log_dir = create_train_folders(\"ml_outputs/run6\")\n",
    "model = Net1()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "sched = None\n",
    "conf1 = {\n",
    "    \"model\": model,\n",
    "    \"optimizer\": opt,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": test_loader,\n",
    "    \"epochs\": 100,\n",
    "    \"ckpt_dir\": ckpt_dir,\n",
    "    \"log_dir\": log_dir,\n",
    "    \"scheduler\": sched,\n",
    "    \"patience\": 30,\n",
    "    \"fname\": \"run1\",\n",
    "    \"label_smooth\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_training(**conf1)\n",
    "\n",
    "# CPU times: user 16min 59s, sys: 54.1 s, total: 17min 53s\n",
    "# Wall time: 17min 33s\n",
    "# {'train_loss': 0.5094659843444824,\n",
    "#  'val_loss': 0.5336426429748535,\n",
    "#  'train_acc': 0.9999833333333333,\n",
    "#  'val_acc': 0.9929}\n",
    "# 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir, log_dir = create_train_folders(\"ml_outputs/run7\")\n",
    "model = Net2()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "sched = None\n",
    "conf1 = {\n",
    "    \"model\": model,\n",
    "    \"optimizer\": opt,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": test_loader,\n",
    "    \"epochs\": 100,\n",
    "    \"ckpt_dir\": ckpt_dir,\n",
    "    \"log_dir\": log_dir,\n",
    "    \"scheduler\": sched,\n",
    "    \"patience\": 30,\n",
    "    \"fname\": \"run1\",\n",
    "    \"label_smooth\": 0.0\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_training(**conf1)\n",
    "\n",
    "# U times: user 9min, sys: 21.7 s, total: 9min 22s\n",
    "# Wall time: 9min 13s\n",
    "# {'train_loss': 0.0065507115011413895,\n",
    "#  'val_loss': 0.029933473259210586,\n",
    "#  'train_acc': 0.9981833333333333,\n",
    "#  'val_acc': 0.9909}\n",
    "# 1\n",
    "# ​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ckpt_dir, log_dir = create_train_folders(\"ml_outputs/run8\")\n",
    "model = Net2()\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "sched = None\n",
    "conf1 = {\n",
    "    \"model\": model,\n",
    "    \"optimizer\": opt,\n",
    "    \"train_loader\": train_loader,\n",
    "    \"val_loader\": test_loader,\n",
    "    \"epochs\": 100,\n",
    "    \"ckpt_dir\": ckpt_dir,\n",
    "    \"log_dir\": log_dir,\n",
    "    \"scheduler\": sched,\n",
    "    \"patience\": 30,\n",
    "    \"fname\": \"run1\",\n",
    "    \"label_smooth\": 0.1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "run_training(**conf1)\n",
    "\n",
    "# PU times: user 19min 30s, sys: 49.4 s, total: 20min 19s\n",
    "# Wall time: 19min 59s\n",
    "# {'train_loss': 0.5131719445546468,\n",
    "#  'val_loss': 0.5369959331512452,\n",
    "#  'train_acc': 0.9999333333333333,\n",
    "#  'val_acc': 0.9927}\n",
    "# 1\n",
    "# ​"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Quantization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.onnx\n",
    "import torch.quantization\n",
    "from ignite.metrics import Accuracy, Loss\n",
    "from ignite.engine import create_supervised_evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _pretty_print(msg):\n",
    "    print(\"*\"*50)\n",
    "    print(msg)\n",
    "    print(\"*\"*50 + \"\\n\")\n",
    "    \n",
    "\n",
    "def print_size_of_model(model, label=\"\"):\n",
    "    torch.save(model.state_dict(), \"temp.p\")\n",
    "    size = os.path.getsize(\"temp.p\")\n",
    "    _pretty_print(f\"model: {label} \\t Size (KB): {size/1e3}\")\n",
    "    os.remove('temp.p')\n",
    "\n",
    "\n",
    "def quantize_trained_model(model, ckpt_dir, test_loader):\n",
    "#     device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    device = torch.device(\"cpu\")\n",
    "    metrics = {\"loss\": Loss(nn.CrossEntropyLoss()), \"acc\": Accuracy()}\n",
    "    \n",
    "    model.load_state_dict(torch.load(glob.glob(os.path.join(ckpt_dir, \"*.pth\"))[0], map_location=device)[\"model\"])\n",
    "    val_evaluator = create_supervised_evaluator(model, metrics=metrics, device=device)\n",
    "    val_evaluator.run(test_loader)\n",
    "    _pretty_print(f\"Metrics before quantization : {val_evaluator.state.metrics}\")\n",
    "\n",
    "    quantized_model = torch.quantization.quantize_dynamic(\n",
    "        model, {nn.Conv2d, nn.Linear, nn.Dropout2d, F.relu, F.max_pool2d}, dtype=torch.qint8\n",
    "    )\n",
    "    \n",
    "    val_evaluator = create_supervised_evaluator(quantized_model, metrics=metrics, device=device)\n",
    "    val_evaluator.run(test_loader)\n",
    "    _pretty_print(f\"Metrics after quantization : {val_evaluator.state.metrics}\")\n",
    "\n",
    "    print_size_of_model(model, \"full model\")\n",
    "    print_size_of_model(quantized_model, \"quantized model\")\n",
    "    \n",
    "    return model, quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Net1()\n",
    "ckpt_dir = \"./ml_outputs/run6/cpkts/\"\n",
    "\n",
    "test_loader = get_dataloader(dataset2, TRAIN_BATCH_SIZE, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**************************************************\n",
      "Metrics before quantization : {'loss': 0.11961191914081573, 'acc': 0.9929}\n",
      "**************************************************\n",
      "\n",
      "**************************************************\n",
      "Metrics after quantization : {'loss': 0.11956824572086334, 'acc': 0.9928}\n",
      "**************************************************\n",
      "\n",
      "**************************************************\n",
      "model: full model \t Size (KB): 4802.487\n",
      "**************************************************\n",
      "\n",
      "**************************************************\n",
      "model: quantized model \t Size (KB): 1261.083\n",
      "**************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, quantized_model = quantize_trained_model(model, ckpt_dir, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantized_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ONNX export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "model = model.to(torch.device(\"cpu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "traced_model = torch.jit.trace(model, dataset1[0][0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net1(\n",
      "  original_name=Net1\n",
      "  (conv1): Conv2d(original_name=Conv2d)\n",
      "  (conv2): Conv2d(original_name=Conv2d)\n",
      "  (dropout1): Dropout2d(original_name=Dropout2d)\n",
      "  (dropout2): Dropout2d(original_name=Dropout2d)\n",
      "  (fc1): Linear(original_name=Linear)\n",
      "  (fc2): Linear(original_name=Linear)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(traced_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "def forward(self,\n",
      "    input: Tensor) -> Tensor:\n",
      "  _0 = self.fc2\n",
      "  _1 = self.dropout2\n",
      "  _2 = self.fc1\n",
      "  _3 = self.dropout1\n",
      "  _4 = self.conv2\n",
      "  input0 = torch.relu((self.conv1).forward(input, ))\n",
      "  input1 = torch.relu((_4).forward(input0, ))\n",
      "  input2 = torch.max_pool2d(input1, [2, 2], annotate(List[int], []), [0, 0], [1, 1], False)\n",
      "  input3 = torch.flatten((_3).forward(input2, ), 1, -1)\n",
      "  input4 = torch.relu((_2).forward(input3, ))\n",
      "  _5 = (_0).forward((_1).forward(input4, ), )\n",
      "  return _5\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(traced_model.code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    tmp = model(dataset1[0][0].unsqueeze(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.2790, -1.3119, -1.2866, -0.5685, -1.4096,  3.7656, -0.9280, -0.8405,\n",
       "         -1.2271, -0.7966]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alka/anaconda3/envs/fastai2/lib/python3.7/site-packages/ipykernel_launcher.py:1: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[0.0060, 0.0058, 0.0060, 0.0122, 0.0053, 0.9309, 0.0085, 0.0093, 0.0063,\n",
       "         0.0097]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.softmax(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset1[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.onnx.export(model,               # model being run\n",
    "                  dataset1[0][0].unsqueeze(0),                         # model input (or a tuple for multiple inputs)\n",
    "                  \"../../public/static/ml_models/mnist.onnx\",   # where to save the model (can be a file or file-like object)\n",
    "                  export_params=True,        # store the trained parameter weights inside the model file\n",
    "                  opset_version=9,          # the ONNX version to export the model to\n",
    "#                   example_outputs=tmp,\n",
    "                  do_constant_folding=True,  # whether to execute constant folding for optimization\n",
    "                  input_names = ['input'],   # the model's input names\n",
    "                  output_names = ['output'], # the model's output names\n",
    "                  dynamic_axes={'input' : {0 : 'batch_size'},    # variable lenght axes\n",
    "                                'output' : {0 : 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnx\n",
    "import onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "onnx_model = onnx.load(\"../../public/static/ml_models/mnist.onnx\")\n",
    "onnx.checker.check_model(onnx_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_numpy(tensor):\n",
    "    return tensor.detach().cpu().numpy() if tensor.requires_grad else tensor.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "ort_session = onnxruntime.InferenceSession(\"../../public/static/ml_models/mnist.onnx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute ONNX Runtime output prediction\n",
    "ort_inputs = {ort_session.get_inputs()[0].name: to_numpy(dataset1[0][0].unsqueeze(0))}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[-1.2789826 , -1.3118939 , -1.2866195 , -0.5685066 , -1.409559  ,\n",
       "          3.7656217 , -0.9280032 , -0.84054834, -1.2270917 , -0.7966455 ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ort_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-1.2790, -1.3119, -1.2866, -0.5685, -1.4096,  3.7656, -0.9280, -0.8405,\n",
      "         -1.2271, -0.7966]])\n"
     ]
    }
   ],
   "source": [
    "print(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported model has been tested with ONNXRuntime, and the result looks good!\n"
     ]
    }
   ],
   "source": [
    "# compare ONNX Runtime and PyTorch results\n",
    "np.testing.assert_allclose(to_numpy(tmp), ort_outs[0], rtol=1e-03, atol=1e-05)\n",
    "\n",
    "print(\"Exported model has been tested with ONNXRuntime, and the result looks good!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('fastai2': conda)",
   "language": "python",
   "name": "python37664bitfastai2conda8980822101d047c8b9d8c08271fb3dfc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
